{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'data/hate_speech_labeled_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  rt mayasolovely as a woman you shouldnt compla...  \n",
      "1  rt mleew17 boy dats coldtyga dwn bad for cuffi...  \n",
      "2  rt urkindofbrand dawg rt 80sbaby4life you ever...  \n",
      "3  rt c_g_anderson viva_based she look like a tranny  \n",
      "4  rt shenikaroberts the shit you hear about me m...  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove special characters, extra spaces, and lowercase the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "df['processed_text'] = df['tweet'].apply(preprocess_text)\n",
    "\n",
    "# Check processed data\n",
    "print(df[['tweet', 'processed_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Function to clean text deeply\n",
    "def deep_preprocess_text(text):\n",
    "    # Remove retweet markers (RT)\n",
    "    text = re.sub(r'\\brt\\b', '', text)\n",
    "    # Remove user mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords (optional)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text  \\\n",
      "0  rt mayasolovely as a woman you shouldnt compla...   \n",
      "1  rt mleew17 boy dats coldtyga dwn bad for cuffi...   \n",
      "2  rt urkindofbrand dawg rt 80sbaby4life you ever...   \n",
      "3  rt c_g_anderson viva_based she look like a tranny   \n",
      "4  rt shenikaroberts the shit you hear about me m...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  mayasolovely woman shouldnt complain cleaning ...  \n",
      "1  mleew17 boy dats coldtyga dwn bad cuffin dat h...  \n",
      "2  urkindofbrand dawg 80sbaby4life ever fuck bitc...  \n",
      "3           c_g_anderson viva_based look like tranny  \n",
      "4  shenikaroberts shit hear might true might fake...  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned_text'] = df['processed_text'].apply(deep_preprocess_text)\n",
    "\n",
    "# Preview the cleaned text\n",
    "print(df[['processed_text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the texts in this dataset are all short sentences with clear boundaries, chunking is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Generate embeddings\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors = \"pt\", truncation = True, max_length = 512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return torch.mean(outputs.last_hidden_state, dim=1).squeeze().numpy()\n",
    "\n",
    "# Generate embeddings for all text\n",
    "df['embeddings'] = df['cleaned_text'].apply(get_embedding)\n",
    "\n",
    "# Save embeddings for reference\n",
    "df.to_pickle('data/hate_speech_embeddings.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>rt mayasolovely as a woman you shouldnt compla...</td>\n",
       "      <td>mayasolovely woman shouldnt complain cleaning ...</td>\n",
       "      <td>[0.09181488, 0.13629913, 0.33594856, 0.0092703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>rt mleew17 boy dats coldtyga dwn bad for cuffi...</td>\n",
       "      <td>mleew17 boy dats coldtyga dwn bad cuffin dat h...</td>\n",
       "      <td>[-0.5987987, 0.2269165, 0.027160339, -0.192366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>rt urkindofbrand dawg rt 80sbaby4life you ever...</td>\n",
       "      <td>urkindofbrand dawg 80sbaby4life ever fuck bitc...</td>\n",
       "      <td>[-0.26544628, -0.0700567, 0.13491961, -0.18819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>rt c_g_anderson viva_based she look like a tranny</td>\n",
       "      <td>c_g_anderson viva_based look like tranny</td>\n",
       "      <td>[-0.26662692, 0.36353925, -0.3158098, 0.163906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>rt shenikaroberts the shit you hear about me m...</td>\n",
       "      <td>shenikaroberts shit hear might true might fake...</td>\n",
       "      <td>[-0.29505986, -0.123553015, -0.050794054, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  rt mayasolovely as a woman you shouldnt compla...   \n",
       "1  rt mleew17 boy dats coldtyga dwn bad for cuffi...   \n",
       "2  rt urkindofbrand dawg rt 80sbaby4life you ever...   \n",
       "3  rt c_g_anderson viva_based she look like a tranny   \n",
       "4  rt shenikaroberts the shit you hear about me m...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  mayasolovely woman shouldnt complain cleaning ...   \n",
       "1  mleew17 boy dats coldtyga dwn bad cuffin dat h...   \n",
       "2  urkindofbrand dawg 80sbaby4life ever fuck bitc...   \n",
       "3           c_g_anderson viva_based look like tranny   \n",
       "4  shenikaroberts shit hear might true might fake...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.09181488, 0.13629913, 0.33594856, 0.0092703...  \n",
       "1  [-0.5987987, 0.2269165, 0.027160339, -0.192366...  \n",
       "2  [-0.26544628, -0.0700567, 0.13491961, -0.18819...  \n",
       "3  [-0.26662692, 0.36353925, -0.3158098, 0.163906...  \n",
       "4  [-0.29505986, -0.123553015, -0.050794054, -0.0...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1% from the df to upsert due to the limit of Pinecone\n",
    "split_index = int(len(df) * 0.01)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "upsert_df = df[:split_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=\"XXXXX\") # Blurred credentials\n",
    "\n",
    "index_name = \"hate-speech-embeddings\"\n",
    "\n",
    "# Create Index\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\",  \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",  \n",
    "        region=\"us-east-1\" \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 247 vectors into the 'hate-speech-embeddings' index.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the created index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Prepare vectors\n",
    "vectors = [ \n",
    "    (str(i), upsert_df['embeddings'][i], {\"label\": int(upsert_df['hate_speech'][i])})\n",
    "    for i in range(len(upsert_df))\n",
    "]\n",
    "\n",
    "# Upsert vectors\n",
    "index.upsert(vectors)\n",
    "print(f\"Upserted {len(vectors)} vectors into the '{index_name}' index.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Query Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_matches(df, query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Function to query Pinecone for similar matches and return corresponding texts from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the original data.\n",
    "    - query_text: The input text to query for similarity.\n",
    "    - index: Pinecone index object.\n",
    "    - top_k: Number of top matches to retrieve (default is 5).\n",
    "    \n",
    "    Returns:\n",
    "    - matched_texts: DataFrame of matched texts.\n",
    "    \"\"\"\n",
    "    # Preprocess the query text\n",
    "    processed_query = deep_preprocess_text(query_text)\n",
    "    query_embedding = get_embedding(processed_query).tolist()\n",
    "    \n",
    "    # Query Pinecone for similarity\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Extract matched IDs from the query results\n",
    "    matched_ids = [int(match['id']) for match in results['matches']]\n",
    "    \n",
    "    # Retrieve the corresponding texts from the DataFrame\n",
    "    matched_texts = df.loc[matched_ids, ['cleaned_text']]\n",
    "    \n",
    "    return matched_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Text: panda express trash wanted chinese didnt feel like gettin car\n",
      "Matched Texts:\n",
      "                                          cleaned_text\n",
      "186                             midwest us white trash\n",
      "222  baskgod main bitches saying hate send pic ass ...\n",
      "196  consprcy_carrot blow shit get fatter white tra...\n",
      "10             drake needs make mind rapper bitch haha\n",
      "95   hate pulling stores niggas staring like never ...\n"
     ]
    }
   ],
   "source": [
    "random_row = df.sample(1, random_state=111)\n",
    "random_query_text = random_row['cleaned_text'].values[0]\n",
    "\n",
    "# Call the function with the random query text\n",
    "matched_texts = find_similar_matches(df, random_query_text, index)\n",
    "\n",
    "# Display the matched texts\n",
    "print(\"Query Text:\", random_query_text)\n",
    "print(\"Matched Texts:\")\n",
    "print(matched_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches makes sense because they are all associated with racial discrimination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_424",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
